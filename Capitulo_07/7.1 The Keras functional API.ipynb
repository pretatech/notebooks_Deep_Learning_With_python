{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de mais nada os notebooks aqui mostrado tiveram como base/foram retirados dos seguintes repositórios: \n",
    " > https://github.com/fchollet/deep-learning-with-python-notebooks \n",
    " \n",
    " \n",
    " > https://github.com/cdfmlr/Deep-Learning-with-Python-Notebooks\n",
    " \n",
    " Sugiro fortemente que consultem os códigos originais e em caso de dúvida podem me contatar para conversarmos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aprendizado profundo com Python\n",
    "\n",
    "## 7.1 Indo além do modelo Sequencial: a API funcional Keras\n",
    "\n",
    "> Solução sem modelo sequencial: API funcional Keras\n",
    "    \n",
    "O modelo sequencial que usamos antes é o modelo mais básico, mas comumente usado. Ele tem apenas uma entrada e uma saída, e toda a rede é formada por empilhamento linear de camadas.\n",
    "\n",
    "No entanto, às vezes nossa rede requer várias entradas. Por exemplo, para prever o preço das roupas, insira as informações do produto, a descrição do texto e as imagens. Esses três tipos de informações devem ser processados pela Dense, RNN e CNN respectivamente. \n",
    "\n",
    "\n",
    "Às vezes, nossa rede requer várias saídas (vários cabeçalhos). Por exemplo, insira um romance, esperamos obter a classificação do romance e adivinhar o tempo de escrita. Este problema deve usar um módulo comum para processar o texto, extrair as informações e, em seguida, submetê-lo ao novo classificador e regressor de data para prever a classificação e o tempo de escrita.\n",
    "\n",
    "Às vezes, algumas redes complexas usam topologias de rede não lineares. Por exemplo, uma coisa chamada Iniciação, a entrada será processada por vários ramos de convolução paralela e, em seguida, as saídas desses ramos são mescladas em um único tensor; há também um método chamado conexão residual (conexão residual), a saída anterior O tensor é adicionado ao tensor de saída subsequente para reinjetar a representação anterior no fluxo de dados downstream para evitar a perda de informações no processo de processamento de informações.\n",
    "\n",
    "Essas redes são semelhantes a gráficos, uma estrutura de rede, ao invés de uma pilha linear como Sequencial. Para implementar este modelo complexo no Keras, você precisa usar a API funcional do Keras.\n",
    "\n",
    "### API Funcional\n",
    "\n",
    "A API funcional de Keras usa camadas como funções, recebe tensores e retorna tensores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "Antes de mais nada os notebooks aqui mostrado tiveram como base/foram retirados dos seguintes repositórios: \n",
    " > https://github.com/fchollet/deep-learning-with-python-notebooks \n",
    " \n",
    " \n",
    " > https://github.com/cdfmlr/Deep-Learning-with-Python-Notebooks\n",
    " \n",
    " Sugiro fortemente que consultem os códigos originais e em caso de dúvida podem me contatar para conversarmos. from tensorflow.keras import Input, layers\n",
    "\n",
    "input_tensor = Input(shape=(32, ))    # Tensor de entrada\n",
    "dense = layers.Dense(32, activation='relu')    # Função de camada\n",
    "output_tensor = dense(input_tensor)   # Tensor de saída "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos construir uma rede simples usando API funcional e comparar com Sequential:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 3,466\n",
      "Trainable params: 3,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Sequential modelo\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "seq_model = Sequential()\n",
    "seq_model.add(layers.Dense(32, activation='relu', input_shape=(64, )))\n",
    "seq_model.add(layers.Dense(32, activation='relu'))\n",
    "seq_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "seq_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 64)]              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 3,466\n",
      "Trainable params: 3,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Modelo de API funcional\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "input_tensor = Input(shape=(64, ))\n",
    "x = layers.Dense(32, activation='relu')(input_tensor)\n",
    "x = layers.Dense(32, activation='relu')(x)\n",
    "output_tensor = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "func_model = Model(input_tensor, output_tensor)\n",
    "\n",
    "func_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quando o objeto Model é instanciado, apenas o tensor de entrada e o tensor de saída obtidos pela transformação do tensor de entrada (através de várias camadas) são fornecidos. Keras encontrará automaticamente cada camada incluída de input_tensor a output_tensor e combinará essas camadas em uma estrutura de dados semelhante a um gráfico - um modelo.\n",
    "\n",
    "Observe que output_tensor deve ser transformado do input_tensor correspondente. Se você usar tensores de entrada e tensores de saída não relacionados para construir o modelo, ValueError desconectado do Graph será explodido (as keras escritas no livro são RuntimeError, tf.keras é ValueError):\n",
    "\n",
    "`` `python\n",
    ">>> unrelated_input = Input (shape = (32,))\n",
    ">>> bad_model = Model (unrelated_input, output_tensor)\n",
    "... # Traceback\n",
    "ValueError: Gráfico desconectado: não é possível obter o valor do tensor Tensor (\"input_2: 0\", shape = (None, 64), dtype = float32) na camada \"dense_4\". As seguintes camadas anteriores foram acessadas sem problemas: []\n",
    "`` `\n",
    "\n",
    "Em outras palavras, é impossível conectar da entrada especificada à saída para formar um gráfico (Gráfico, o tipo de estrutura de dados, o tipo de rede).\n",
    "\n",
    "Para a rede construída por esta API funcional, a compilação, treinamento ou avaliação são iguais a Sequencial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 33.5245\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 38.1499\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 42.0662\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 46.1707\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 0s 813us/step - loss: 50.6095\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 54.8778\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 59.6547\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 64.5255\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 69.2659\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 0s 685us/step - loss: 74.5707\n",
      "32/32 [==============================] - 0s 617us/step - loss: 78.1296\n"
     ]
    }
   ],
   "source": [
    "# Compilar\n",
    "func_model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "\n",
    "# Dados de treinamento aleatórios\n",
    "import numpy as np\n",
    "x_train = np.random.random((1000, 64))\n",
    "y_train = np.random.random((1000, 10))\n",
    "\n",
    "# Treinamento\n",
    "func_model.fit(x_train, y_train, epochs=10, batch_size=128)\n",
    "\n",
    "# Avaliação\n",
    "score = func_model.evaluate(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo de múltiplas entradas\n",
    "\n",
    "APIs funcionais podem ser usadas para construir modelos com várias entradas. Modelos com várias entradas geralmente combinam diferentes ramificações com uma camada que pode combinar tensores em um determinado ponto. Para combinar tensores, você pode usar adição, concatenação, etc. Camadas como `keras.layers.add` e` keras.layers.concatenate` são fornecidas no keras para completar essas operações.\n",
    "\n",
    "Veja um exemplo específico e faça um modelo de perguntas e respostas. Um modelo típico de resposta a perguntas usa duas entradas:\n",
    "\n",
    "- Texto da pergunta\n",
    "- Fornece texto informativo para responder a perguntas (como artigos de notícias relacionados)\n",
    "\n",
    "O modelo precisa gerar (produzir) uma resposta. O caso mais simples é responder apenas uma palavra.Podemos obter o resultado enfrentando algum vocabulário predefinido e tornando a saída softmax.\n",
    "\n",
    "Para implementar este modelo com API funcional, primeiro construímos dois ramos independentes, representamos o texto de referência e a pergunta como vetores respectivamente, em seguida, conectamos esses dois vetores e adicionamos um classificador softmax à representação após a conexão ser concluída:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"QA\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "text (InputLayer)               [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "question (InputLayer)           [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_13 (Embedding)        (None, None, 64)     640000      text[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_14 (Embedding)        (None, None, 32)     320000      question[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_13 (LSTM)                  (None, 32)           12416       embedding_13[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_14 (LSTM)                  (None, 16)           3136        embedding_14[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 48)           0           lstm_13[0][0]                    \n",
      "                                                                 lstm_14[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 500)          24500       concatenate_6[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,000,052\n",
      "Trainable params: 1,000,052\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Input\n",
    "\n",
    "text_vocabulary_size = 10000\n",
    "question_vocabulary_size = 10000\n",
    "answer_vocabulary_size = 500\n",
    "\n",
    "# referência\n",
    "text_input = Input(shape=(None, ), dtype='int32', name='text')\n",
    "embedded_text = layers.Embedding(text_vocabulary_size, 64)(text_input)\n",
    "encoded_text = layers.LSTM(32)(embedded_text)\n",
    "\n",
    "# problema\n",
    "question_input = Input(shape=(None, ), dtype='int32', name='question')\n",
    "embedded_question = layers.Embedding(question_vocabulary_size, 32)(question_input)\n",
    "encoded_question = layers.LSTM(16)(embedded_question)\n",
    "\n",
    "# Mesclando referências, ramificações com problemas\n",
    "concatenated = layers.concatenate([encoded_text, encoded_question], axis=-1)\n",
    "\n",
    "# Classificador de nível superior\n",
    "answer = layers.Dense(anser_vocabulary_size, activation='softmax')(concatenated)\n",
    "\n",
    "model = Model([text_input, question_input], answer, name='QA')\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='rmsprop', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao treinar este modelo de múltiplas entradas, você pode transferi-lo para uma lista de componentes e também pode transferir um dicionário para a entrada com um nome especificado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 1/2\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13e55f9d0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_samples = 1000\n",
    "max_length = 100\n",
    "\n",
    "text = np.random.randint(1, text_vocabulary_size, \n",
    "                         size=(num_samples, max_length))\n",
    "question = np.random.randint(1, question_vocabulary_size, \n",
    "                             size=(num_samples, max_length))\n",
    "answers = np.random.randint(0, 1, \n",
    "                            size=(num_samples, answer_vocabulary_size)) # one-hot Codificado\n",
    "\n",
    "# Método 1. Lista de upload\n",
    "model.fit([text, question], answers, epochs=2, batch_size=128)\n",
    "\n",
    "# Método 2. Transferir um dicionário\n",
    "model.fit({'text': text, 'question': question}, answers, epochs=2, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo de múltiplas saídas\n",
    "\n",
    "Também é conveniente usar APIs funcionais para construir modelos com várias saídas (multi-heads). Por exemplo, vamos fazer uma rede que tenta prever a natureza diferente dos dados ao mesmo tempo: insira algumas postagens de mídia social de alguém e tente prever os atributos de idade, sexo e nível de renda dessa pessoa:\n",
    "\n",
    "A implementação específica é muito simples, basta escrever 3 saídas diferentes no final:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "posts (InputLayer)              [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_15 (Embedding)        (None, None, 50000)  12800000    posts[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, None, 128)    32000128    embedding_15[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, None, 128)    0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, None, 256)    164096      max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, None, 256)    327936      conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, None, 256)    0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, None, 256)    327936      max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, None, 256)    327936      conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d (GlobalMax (None, 256)          0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 128)          32896       global_max_pooling1d[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "age (Dense)                     (None, 1)            129         dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "income (Dense)                  (None, 10)           1290        dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gender (Dense)                  (None, 1)            129         dense_14[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 45,982,476\n",
      "Trainable params: 45,982,476\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, GlobalMaxPool1D, Dense\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "vocabulary_size = 50000\n",
    "num_income_groups = 10\n",
    "\n",
    "posts_input = Input(shape=(None,), dtype='int32', name='posts')\n",
    "embedded_post = layers.Embedding(256, vocabulary_size)(posts_input)\n",
    "x = Conv1D(128, 5, activation='relu')(embedded_post)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(256, 5, activation=\"relu\")(x)\n",
    "x = Conv1D(256, 5, activation=\"relu\")(x)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(256, 5, activation=\"relu\")(x)\n",
    "x = Conv1D(256, 5, activation=\"relu\")(x)\n",
    "x = GlobalMaxPool1D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "\n",
    "# Defina vários cabeçalhos (saída)\n",
    "age_prediction = Dense(1, name='age')(x)\n",
    "income_prediction = Dense(num_income_groups, activation='softmax', name='income')(x)\n",
    "gender_prediction = Dense(1, activation='sigmoid', name='gender')(x)\n",
    "\n",
    "model = Model(posts_input, [age_prediction, income_prediction, gender_prediction])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Compilação de modelo de várias cabeças **\n",
    "\n",
    "Ao compilar este modelo, porque existem objetivos diferentes, deve-se observar que diferentes funções de perda precisam ser especificadas para cada cabeça da rede.\n",
    "\n",
    "Mas o papel da descida gradiente só pode ser minimizar um escalar, então em Keras, as diferentes perdas especificadas para diferentes saídas em tempo de compilação serão adicionadas para obter uma perda global durante o treinamento. O processo de treinamento é para minimizar esta perda global 化.\n",
    "\n",
    "Nesse caso, se a contribuição da perda for gravemente desequilibrada, o modelo priorizará a tarefa com o maior valor de perda, sem considerar as outras tarefas. Para resolver este problema, diferentes perdas podem ser ponderadas. Por exemplo, o valor de perda de mse é geralmente 3 ~ 5 e o valor de perda de binary_crossentropy é geralmente tão baixo quanto 0,1. Para equilibrar a contribuição de perda, podemos fazer o peso de binary_crossentropy 10 e o peso de perda de mse 0,5.\n",
    "\n",
    "A atribuição de múltiplas perdas e pesos é feita usando listas ou dicionários:\n",
    "```python\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss=['mse', 'categorical_crossentropy', 'binary_crossentropy'],\n",
    "              loss_weights=[0.25, 1., 10.])\n",
    "\n",
    "# Ou se você nomear a camada de saída, pode usar um dicionário:\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss={'age': 'mse',\n",
    "                    'income': 'categorical_crossentropy',\n",
    "                    'gender': 'binary_crossentropy'},\n",
    "              loss_weights={'age': 0.25,\n",
    "                            'income': 1.,\n",
    "                            'gender': 10.})\n",
    "```\n",
    "\n",
    "** Treinamento do modelo multi-head **\n",
    "\n",
    "Ao treinar este modelo, basta passar a saída de destino em uma lista ou dicionário:\n",
    "\n",
    "```python\n",
    "model.fit(posts, [age_targets, income_targets, gender_targets],\n",
    "          epochs=10, batch_size=64)\n",
    "\n",
    "# or\n",
    "\n",
    "model.fit(posts, {'age': age_targets,\n",
    "                  'income': income_targets,\n",
    "                  'gender': gender_targets},\n",
    "          epochs=10, batch_size=64)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráfico Acíclico Direcionado em Camadas\n",
    "\n",
    "Usando APIs funcionais, além de construir modelos de múltiplas entradas e saídas, também podemos implementar redes com topologias internas complexas.\n",
    "\n",
    "Na verdade, a rede neural em Keras pode ser qualquer gráfico acíclico direcionado composto de camadas. Os componentes da estrutura gráfica mais conhecidos incluem o módulo de iniciação e a conexão residual.\n",
    "\n",
    "#### Módulo de iniciação\n",
    "\n",
    "A iniciação é uma pilha de módulos, cada um parecendo uma pequena rede independente, esses módulos são divididos em vários ramos paralelos e, finalmente, os recursos resultantes são conectados entre si. Essa operação permite que a rede aprenda os recursos espaciais e os recursos canal a canal da imagem separadamente, o que é mais eficaz do que usar uma rede para aprender esses recursos ao mesmo tempo.\n",
    "\n",
    "> Observação: a convolução 1x1 usada aqui é chamada de convolução pontual, que é um recurso do módulo de Iniciação.\n",
    "> Ele olha apenas para um pixel por vez, e os recursos calculados podem misturar as informações nos canais de entrada, mas não as informações espaciais.\n",
    "> Desta forma, é feita uma distinção entre aprendizagem de recursos de canal e aprendizagem de recursos espaciais.\n",
    "\n",
    "Isso pode ser alcançado com uma API funcional:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "x = Input(shape=(None, None, 3))    # Imagem RGB\n",
    "\n",
    "branch_a = layers.Conv2D(128, 1, activation='relu', strides=2, padding='same')(x)\n",
    "\n",
    "branch_b = layers.Conv2D(128, 1, activation='relu', padding='same')(x)\n",
    "branch_b = layers.Conv2D(128, 3, activation='relu', strides=2, padding='same')(branch_b)\n",
    "\n",
    "branch_c = layers.AveragePooling2D(3, strides=2, padding='same')(x)\n",
    "branch_c = layers.Conv2D(128, 3, activation='relu', padding='same')(branch_c)\n",
    "\n",
    "branch_d = layers.Conv2D(128, 1, activation='relu', padding='same')(x)\n",
    "branch_d = layers.Conv2D(128, 3, activation='relu', padding='same')(branch_d)\n",
    "branch_d = layers.Conv2D(128, 3, activation='relu', strides=2, padding='same')(branch_d)\n",
    "\n",
    "output = layers.concatenate([branch_a, branch_b, branch_c, branch_d], axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na verdade, Keras tem uma arquitetura Inception V3 completa integrada. Ele pode ser chamado por `keras.applications.inception_v3.InceptionV3`.\n",
    "\n",
    "Relacionado ao Inception, existe outra coisa chamada ** Xception **. A palavra Xception significa início extremo. É um tipo de início extremo, que separa completamente o aprendizado de recursos de canal do aprendizado de recursos espaciais. O número de parâmetros do Xception é aproximadamente o mesmo do Inception V3, mas seu uso de parâmetros é mais eficiente, portanto, tem melhor desempenho e maior precisão em conjuntos de dados de grande escala.\n",
    "\n",
    "#### Conexão residual\n",
    "\n",
    "A conexão residual (conexão residual) é um componente muito comumente usado agora, ele resolve o problema de desaparecimento e gargalo do gradiente do modelo de aprendizagem profunda em larga escala. Em geral, adicionar conexões residuais a qualquer modelo com mais de 10 camadas pode ajudar.\n",
    "\n",
    "- Desaparecimento de radiação: há mais camadas passadas e a representação aprendida anteriormente torna-se borrada ou mesmo completamente perdida, fazendo com que a rede falhe no treinamento.\n",
    "-Indica um gargalo: empilhar camadas, a última camada só pode acessar as coisas aprendidas na camada anterior. Se uma determinada camada for muito pequena (menos informações podem ser inseridas na ativação), as informações serão cardadas e um gargalo aparecerá.\n",
    "\n",
    "A conexão residual é permitir a saída de uma camada anterior como a entrada de uma camada posterior (criando um atalho na rede). A saída da camada anterior não está conectada com a ativação da última camada, mas é adicionada à ativação da última camada (se a forma for diferente, use uma transformação linear para alterar a ativação da camada anterior na forma de destino).\n",
    "\n",
    "> Observação: a transformação linear pode usar a camada Densa sem ativação ou usar a convolução 1 × 1 sem ativação no CNN.\n",
    "\n",
    "```python\n",
    "from keras import layers\n",
    "\n",
    "x = ...\n",
    "\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(x)\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(y)\n",
    "y = layers.MaxPooling2D(2, strides=2)(y)\n",
    "\n",
    "# Formas diferentes, faça transformação linear:\n",
    "residual = layers.Conv2D(128, 1, strides=2, padding='same')(x)  # Use a convolução 1 × 1 para reduzir linearmente x para ter a mesma forma que y\n",
    "\n",
    "y = layers.add([y, residual])\n",
    "```\n",
    "\n",
    "#### Peso da camada compartilhada\n",
    "\n",
    "Usando APIs funcionais, outra operação é usar uma instância de camada várias vezes. Se você chamar a mesma instância de camada várias vezes, poderá reutilizar o mesmo peso. Usando este recurso, um modelo com ramificações compartilhadas pode ser construído, ou seja, várias ramificações compartilham o mesmo conhecimento e realizam as mesmas operações.\n",
    "\n",
    "Por exemplo, queremos avaliar a semelhança semântica entre duas frases. Este modelo usa duas frases como entrada e produz uma pontuação que varia de 0 a 1. Quanto maior o valor, mais semelhante é o significado da frase.\n",
    "\n",
    "Neste problema, as duas sentenças de entrada são intercambiáveis ​​(a similaridade da sentença A com B é igual à similaridade de B com A). Portanto, dois modelos separados não devem ser aprendidos a processar duas sentenças de entrada separadamente. Em vez disso, uma camada LSTM deve ser usada para processar duas frases. A representação (peso) desta camada LSTM é aprendida de duas entradas ao mesmo tempo. Este modelo é denominado Siamese LSTM (Siamese LSTM) ou LSTM compartilhado (LSTM compartilhado).\n",
    "\n",
    "Esse modelo é implementado usando o compartilhamento de camadas na API funcional Keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_8\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_13 (InputLayer)           [(None, None, 128)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_14 (InputLayer)           [(None, None, 128)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_15 (LSTM)                  (None, 32)           20608       input_13[0][0]                   \n",
      "                                                                 input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 64)           0           lstm_15[0][0]                    \n",
      "                                                                 lstm_15[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 1)            65          concatenate_13[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 20,673\n",
      "Trainable params: 20,673\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "lstm = layers.LSTM(32)  # Instancie apenas um LSTM\n",
    "\n",
    "left_input = Input(shape=(None, 128))\n",
    "left_output = lstm(left_input)\n",
    "\n",
    "right_input = Input(shape=(None, 128))\n",
    "right_output = lstm(right_input)\n",
    "\n",
    "merged = layers.concatenate([left_output, right_output], axis=-1)\n",
    "predictions = layers.Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "model = Model([left_input, right_input], predictions)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use o modelo como uma camada\n",
    "\n",
    "No Keras, podemos usar o modelo como uma camada (o fenômeno do modelo é uma camada grande) e as classes Sequential e Model podem ser usadas como camadas. Basta chamá-lo funcionalmente como uma camada:\n",
    "\n",
    "`` `python\n",
    "y = modelo (x)\n",
    "y1, y2 = model_with_multi_inputs_and_outputs ([x1, x2])\n",
    "`` `\n",
    "\n",
    "Por exemplo, processamos um modelo visual com câmeras duplas como entrada (este modelo pode perceber a profundidade). Usamos o modelo applications.Xception como a camada e usamos o método de camada compartilhada anterior para implementar esta rede:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras import applications\n",
    "\n",
    "xception_base = applications.Xception(weights=None, include_top=False)\n",
    "\n",
    "left_input = Input(shape=(250, 250, 3))\n",
    "right_input = Input(shape=(250, 250, 3))\n",
    "\n",
    "left_features = xception_base(left_input)\n",
    "right_input = xception_base(right_input)\n",
    "\n",
    "merged_features = layers.concatenate([left_features, right_input], axis=-1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
