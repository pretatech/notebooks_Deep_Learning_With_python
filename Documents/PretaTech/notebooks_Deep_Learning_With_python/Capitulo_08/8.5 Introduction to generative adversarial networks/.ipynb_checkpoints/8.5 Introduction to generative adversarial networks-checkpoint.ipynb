{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aprendizado profundo com Python\n",
    "\n",
    "## 8.5 IntroduÃ§Ã£o Ã s redes adversÃ¡rias geradoras\n",
    "\n",
    "> IntroduÃ§Ã£o Ã s Redes Adversariais Gerativas\n",
    "\n",
    "GAN, chinÃªs Ã© ~~ gan ~~, errado, Generative Adversarial Network. Como VAE, Ã© usado para aprender o espaÃ§o latente da imagem. Isso pode tornar a imagem gerada \"estatisticamente\" igual Ã  imagem real, ou seja, a imagem gerada Ã© bastante realista. No entanto, ao contrÃ¡rio do VAE, o espaÃ§o latente de GAN nÃ£o pode ser garantido como tendo uma estrutura significativa e nÃ£o Ã© contÃ­nuo.\n",
    "\n",
    "GAN consiste em duas partes:\n",
    "\n",
    "-Rede geradora: insira um vetor aleatÃ³rio (um ponto aleatÃ³rio no espaÃ§o latente) e decodifique-o em uma imagem.\n",
    "- Rede discriminadora: Insira uma imagem (real ou desenhada pelo gerador) e preveja se a imagem Ã© real ou criada pela rede do gerador. (A rede discriminadora tambÃ©m Ã© chamada de \"adversÃ¡rio\", adversÃ¡rio)\n",
    "\n",
    "O objetivo do treinamento do GAN Ã© permitir que a \"rede geradora\" engane a \"rede discriminadora\".\n",
    "\n",
    "A compreensÃ£o intuitiva de GAN Ã© uma histÃ³ria muito inspiradora: ou seja, hÃ¡ duas pessoas, um falsificador e um avaliador. Os falsificadores imitam as pinturas do mestre e, em seguida, misturam suas imitaÃ§Ãµes com as originais e as submetem ao avaliador para avaliaÃ§Ã£o, que avalia a autenticidade de cada pintura e vÃª atravÃ©s de quais sÃ£o forjadas. O amÃ¡vel avaliador deu feedback ao falsificador e disse-lhe as caracterÃ­sticas do original. Os falsificadores irÃ£o, passo a passo, melhorar sua capacidade de falsificaÃ§Ã£o com base nas opiniÃµes do avaliador. Os dois repetiram esse processo incansavelmente: os falsificadores tornaram-se cada vez mais bons em copiar pinturas de mestres e os avaliadores se tornaram cada vez mais bons em encontrar pinturas falsas. No final, os falsificadores criaram um lote de \"produtos de imitaÃ§Ã£o\" que os avaliadores impÃµem.\n",
    "\n",
    "! [O gerador converte o vetor latente aleatÃ³rio em uma imagem e o discriminador tenta distinguir a imagem real da imagem gerada. O gerador Ã© treinado para enganar o discriminador] (https://tva1.sinaimg.cn/large/007S8ZIlgy1ghva0rve82j31ec0tcthm.jpg)\n",
    "\n",
    "O mÃ©todo de treinamento do GAN Ã© muito especial e seu mÃ­nimo otimizado nÃ£o Ã© fixo. Nossa \"descida gradiente\" usual Ã© rolar montanha abaixo ao longo do terreno de perda estÃ¡tica, mas cada degrau da montanha durante o treinamento GAN mudarÃ¡ todo o terreno. Ã‰ um sistema dinÃ¢mico e seu processo de otimizaÃ§Ã£o Ã© o equilÃ­brio entre duas forÃ§as. Portanto, GAN Ã© difÃ­cil de treinar. Para fazer o GAN funcionar normalmente, Ã© necessÃ¡rio muito trabalho de construÃ§Ã£o de modelo e ajuste de hiperparÃ¢metro.\n",
    "\n",
    "### Rede Adversarial Gerativa Convolucional Profunda\n",
    "\n",
    "Vamos tentar implementar o GAN mais simples e simples com Keras. Especificamente, construiremos uma ** rede convolucional profunda de confronto gerador ** (GAN convolucional profunda, DCGAN). O gerador e o discriminador desse tipo de coisa sÃ£o ambas redes neurais convolucionais profundas.\n",
    "\n",
    "Vamos treinar DCGAN com imagens da categoria \"sapo\" no conjunto de dados CIFAR10. Este conjunto de dados contÃ©m 50000 imagens RGB 32 Ã— 32, que pertencem a 10 categorias (5000 imagens em cada categoria).\n",
    "\n",
    "#### Processo de implementaÃ§Ã£o\n",
    "\n",
    "1. A rede `generator` mapeia um vetor de forma` (latent_dim,) `para uma imagem de forma` (32, 32, 3) `.\n",
    "2. A rede `discriminator` mapeia a imagem com a forma` (32, 32, 3) `para uma pontuaÃ§Ã£o binÃ¡ria, que Ã© usada para avaliar a probabilidade de a imagem ser verdadeira.\n",
    "3. A rede `gan` conecta` gerador` e `discriminador` juntos:` gan (x) = discriminador (gerador (x)) `. Esta rede mapeia o vetor latente para o resultado da avaliaÃ§Ã£o do discriminador.\n",
    "4. Use as amostras de imagens verdadeiras e falsas rotuladas com `\" real \"` ou `\" falsa \"` para treinar o discriminador e use o mÃ©todo usual de treinar modelos de classificaÃ§Ã£o de imagem comuns.\n",
    "5. Para treinar o gerador, use o gradiente de perda do modelo `gan` em relaÃ§Ã£o ao peso do gerador. A cada etapa, o peso do gerador deve ser movido para \"tornar o discriminador mais provÃ¡vel de classificar a imagem decodificada pelo gerador como\" verdadeira \"\", ou seja, treinar o gerador para enganar o discriminador.\n",
    "\n",
    "#### Habilidades prÃ¡ticas\n",
    "\n",
    "O processo de treinamento e ajuste do GAN Ã© muito difÃ­cil. Portanto, precisamos nos lembrar de algumas habilidades prÃ¡ticas resumidas por pessoas anteriores. Essas tÃ©cnicas geralmente sÃ£o Ãºteis, mas nÃ£o se aplicam a todas as situaÃ§Ãµes. Essas coisas nÃ£o tÃªm base teÃ³rica, sÃ£o todas metafÃ­sicas, entÃ£o escreva a conclusÃ£o diretamente, sem explicaÃ§Ã£o:\n",
    "\n",
    "-Use tanh como a ativaÃ§Ã£o da Ãºltima camada do gerador em vez de sigmÃ³ide.\n",
    "-Use a distribuiÃ§Ã£o normal (distribuiÃ§Ã£o gaussiana) para amostrar pontos no espaÃ§o latente em vez da distribuiÃ§Ã£o uniforme.\n",
    "-A aleatoriedade pode melhorar a robustez. O treinamento GAN pode ficar \"preso\" de vÃ¡rias maneiras (atingindo o equilÃ­brio dinÃ¢mico errado). A introduÃ§Ã£o da aleatoriedade durante o processo de treinamento ajuda a prevenir essa situaÃ§Ã£o. Existem duas maneiras de introduzir a aleatoriedade:\n",
    "    1. Use dropout no discriminador;\n",
    "    2. Adicione ruÃ­do aleatÃ³rio ao rÃ³tulo do discriminador;\n",
    "- Gradiente esparso atrapalharÃ¡ o treinamento GAN \"OperaÃ§Ã£o mÃ¡xima de pooling\" e \"ativaÃ§Ã£o ReLU\" podem levar a gradientes esparsos, por isso Ã© recomendado:\n",
    "    1. Use `` convoluÃ§Ã£o em etapas '' ao invÃ©s de `` max pooling '' para reduzir a resoluÃ§Ã£o;\n",
    "    2. Use a camada LeakyReLU para substituir a ativaÃ§Ã£o ReLU;\n",
    "-Nas imagens geradas, artefatos quadriculados sÃ£o frequentemente vistos, o que se deve Ã  cobertura desigual do espaÃ§o do pixel no gerador. A soluÃ§Ã£o para este problema Ã©: sempre que o passo Conv2DTranpose ou Conv2D Ã© usado no gerador e discriminador, o tamanho do kernel deve ser divisÃ­vel pelo passo.\n",
    "\n",
    "\n",
    "\n",
    "Imagem de exemplo de artefatos de tabuleiro de xadrez devido Ã  incompatibilidade de tamanho da passada e tamanho do kernel:\n",
    "\n",
    "! [Artefatos do tabuleiro de damas devido Ã  incompatibilidade de tamanho da passada e tamanho do kernel] (https://tva1.sinaimg.cn/large/007S8ZIlgy1ghvayd7ipwj31560ggazl.jpg)\n",
    "\n",
    "#### A realizaÃ§Ã£o do gerador\n",
    "\n",
    "Comecei a construir o primeiro GAN para jovens! !\n",
    "\n",
    "Primeiro desenvolva o modelo do gerador: converta o vetor do espaÃ§o latente em uma imagem candidata.\n",
    "\n",
    "Para evitar \"travar\" durante o treinamento, o dropout Ã© usado tanto no discriminador quanto no gerador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32)]              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32768)             1081344   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 16, 16, 256)       819456    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 32, 32, 256)       1048832   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 256)       1638656   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 256)       1638656   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 3)         37635     \n",
      "=================================================================\n",
      "Total params: 6,264,579\n",
      "Trainable params: 6,264,579\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# GAN Rede Geradora\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "height = 32\n",
    "width = 32\n",
    "channels = 3\n",
    "\n",
    "latent_dim = 32\n",
    "\n",
    "generator_input = keras.Input(shape=(latent_dim,))\n",
    "\n",
    "# Converta a entrada em um mapa de recursos de 128 canais com um tamanho de 16 Ã— 16\n",
    "x = layers.Dense(128 * 16 * 16)(generator_input)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Reshape((16, 16, 128))(x)\n",
    "\n",
    "x = layers.Conv2D(256, 5, padding='same')(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "# A amostragem de aumento Ã© de 32 Ã— 32\n",
    "x = layers.Conv2DTranspose(256, 4, strides=2, padding='same')(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Conv2D(256, 5, padding='same')(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2D(256, 5, padding='same')(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "# Gere um mapa de recursos de tamanho 32 Ã— 32 (o formato da imagem CIFAR10)\n",
    "x = layers.Conv2D(channels, 7, activation='tanh', padding='same')(x)\n",
    "\n",
    "generator = keras.models.Model(generator_input, x)\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ImplementaÃ§Ã£o do discriminador\n",
    "\n",
    "Em seguida, desenvolva o modelo discriminador, insira uma imagem (real ou sintÃ©tica) e divida-a em \"verdadeiro\" (imagem real do conjunto de treinamento) ou \"falso\" (imagem desenhada pelo gerador)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 30, 30, 128)       3584      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 30, 30, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 14, 14, 128)       262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 6, 6, 128)         262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 2, 2, 128)         262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 790,913\n",
      "Trainable params: 790,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# GAN Rede discriminadora\n",
    "\n",
    "discriminator_input = layers.Input(shape=(height, width, channels))\n",
    "\n",
    "x = layers.Conv2D(128, 3)(discriminator_input)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Conv2D(128, 4, strides=2)(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Conv2D(128, 4, strides=2)(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Conv2D(128, 4, strides=2)(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dropout(0.4)(x)\n",
    "\n",
    "x = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "discriminator = keras.models.Model(discriminator_input, x)\n",
    "discriminator.summary()\n",
    "\n",
    "discriminator_optimizer = keras.optimizers.RMSprop(\n",
    "    lr=0.0008,\n",
    "    clipvalue=1.0,\n",
    "    decay=1e-8)\n",
    "\n",
    "discriminator.compile(optimizer=discriminator_optimizer,\n",
    "                      loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confrontando a Internet\n",
    "\n",
    "Finalmente, configure o GAN, conecte o gerador e o discriminador e converta os pontos no espaÃ§o latente em um julgamento de classificaÃ§Ã£o verdadeiro ou falso.\n",
    "\n",
    "Ao treinar este modelo, Ã© necessÃ¡rio congelar o â€œdiscriminadorâ€ (tornÃ¡-lo intratÃ¡vel), e apenas permitir que o â€œgeradorâ€ se mova na direÃ§Ã£o de â€œmelhorar a habilidade do discriminador de enganoâ€.\n",
    "\n",
    "Ao treinar gan, tudo o que usamos sÃ£o os rÃ³tulos de \"imagens reais\", portanto, se o peso do \"discriminador\" puder ser atualizado durante o processo de treinamento, o treinamento farÃ¡ com que o discriminador sempre preveja \"verdadeiro\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rede de Confronto\n",
    "\n",
    "discriminator.trainable = False    # Isso sÃ³ funcionarÃ¡ em gan\n",
    "\n",
    "gan_input = keras.Input(shape=(latent_dim,))\n",
    "gan_output = discriminator(generator(gan_input))\n",
    "gan = keras.models.Model(gan_input, gan_output)\n",
    "\n",
    "gan_optimizer = keras.optimizers.RMSprop(\n",
    "    lr=0.0004,\n",
    "    clipvalue=1.0,\n",
    "    decay=1e-8)\n",
    "gan.compile(optimizer=gan_optimizer,\n",
    "            loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treine DCGAN\n",
    "\n",
    "O fluxo do loop de treinamento Ã© o seguinte:\n",
    "\n",
    "1. Extraia pontos aleatÃ³rios (ruÃ­do aleatÃ³rio) do espaÃ§o latente.\n",
    "2. DÃª este ruÃ­do aleatÃ³rio ao gerador para gerar uma imagem.\n",
    "3. Misture a imagem gerada com a imagem real.\n",
    "4. Use essas imagens misturadas e os rÃ³tulos correspondentes (a imagem real Ã© \"verdadeira\" e a imagem gerada Ã© \"falsa\") para treinar o discriminador.\n",
    "5. Desenhe aleatoriamente novos pontos no espaÃ§o latente.\n",
    "6. Use esses vetores e rÃ³tulos aleatÃ³rios que sÃ£o \"imagens reais\" para treinar gan.\n",
    "\n",
    "ImplementaÃ§Ã£o de cÃ³digo especÃ­fico:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: discriminator loss: 0.6944685578346252, adversarial loss: 0.7566524744033813\n",
      "step 50: discriminator loss: 0.6997207999229431, adversarial loss: 0.7283448576927185\n",
      "step 100: discriminator loss: 0.6917451024055481, adversarial loss: 0.7818207144737244\n",
      "step 150: discriminator loss: 0.7006672620773315, adversarial loss: 0.77472984790802\n",
      "step 200: discriminator loss: 0.6959202885627747, adversarial loss: 0.7540444731712341\n",
      "step 250: discriminator loss: 0.6907225847244263, adversarial loss: 0.7319836020469666\n",
      "step 300: discriminator loss: 0.6964272856712341, adversarial loss: 0.795426070690155\n",
      "step 350: discriminator loss: 0.7021819949150085, adversarial loss: 0.7412662506103516\n",
      "step 400: discriminator loss: 0.6954243183135986, adversarial loss: 0.7441832423210144\n",
      "step 450: discriminator loss: 0.7256754636764526, adversarial loss: 0.7400968074798584\n",
      "step 500: discriminator loss: 0.7020201683044434, adversarial loss: 0.7446410059928894\n",
      "step 550: discriminator loss: 0.6801480054855347, adversarial loss: 0.9143943786621094\n",
      "step 600: discriminator loss: 0.6830952763557434, adversarial loss: 0.7880680561065674\n",
      "step 650: discriminator loss: 0.7454708218574524, adversarial loss: 0.782561182975769\n",
      "step 700: discriminator loss: 0.6792200803756714, adversarial loss: 0.7939407825469971\n",
      "step 750: discriminator loss: 0.6916797757148743, adversarial loss: 0.8157812356948853\n",
      "step 800: discriminator loss: 0.6902390718460083, adversarial loss: 0.750106692314148\n",
      "step 850: discriminator loss: 0.6986071467399597, adversarial loss: 0.7653893232345581\n",
      "step 900: discriminator loss: 0.7069215774536133, adversarial loss: 0.7258030772209167\n",
      "step 950: discriminator loss: 0.6925474405288696, adversarial loss: 0.7341045141220093\n",
      "999/1000: 12.41s - ETA: 12ss\r"
     ]
    }
   ],
   "source": [
    "# GAN Treinamento,\n",
    "\n",
    "import os\n",
    "import time\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Importar dados CIFAR10\n",
    "(x_train, y_train), (_, _) = keras.datasets.cifar10.load_data()\n",
    "# Selecione a imagem do sapoğŸ¸\n",
    "x_train = x_train[y_train.flatten() == 6]\n",
    "\n",
    "x_train = x_train.reshape(\n",
    "    (x_train.shape[0],) + (height, width, channels)\n",
    ").astype('float32') / 255.\n",
    "\n",
    "\n",
    "iterations = 10000\n",
    "batch_size = 20\n",
    "save_dir = 'gan_save'\n",
    "\n",
    "start = 0\n",
    "for step in range(iterations+1):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Amostra aleatoriamente de pontos potenciais\n",
    "    random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\n",
    "    \n",
    "    # Gerar imagem\n",
    "    generated_images = generator.predict(random_latent_vectors)\n",
    "    \n",
    "    # Escolha uma imagem real\n",
    "    stop = start + batch_size\n",
    "    real_images = x_train[start: stop]\n",
    "    \n",
    "    # Combine imagens reais e geradas e dÃª rÃ³tulos\n",
    "    combined_images = np.concatenate([generated_images, real_images])\n",
    "    labels = np.concatenate([np.ones((batch_size, 1)),\n",
    "                             np.zeros((batch_size, 1))])\n",
    "    labels += 0.05 * np.random.random(labels.shape)  # Adicionar ruÃ­do aleatÃ³rio ao rÃ³tulo\n",
    "    \n",
    "    # è®­ç»ƒåˆ¤åˆ«å™¨\n",
    "    d_loss = discriminator.train_on_batch(combined_images, labels)\n",
    "    \n",
    "    # éšæœºé‡‡æ ·æ½œåœ¨ç‚¹\n",
    "    random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\n",
    "    \n",
    "    misleading_targets = np.zeros((batch_size, 1))  # è°ç§°å…¨éƒ¨éƒ½æ˜¯çœŸå®å›¾ç‰‡\n",
    "    \n",
    "    # é€šè¿‡ gan æ¨¡å‹è®­ç»ƒç”Ÿæˆå™¨\n",
    "    a_loss = gan.train_on_batch(random_latent_vectors, misleading_targets)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    start += batch_size\n",
    "    if start > len(x_train) - batch_size:\n",
    "        start = 0\n",
    "        \n",
    "    if step % 50 == 0:\n",
    "        gan.save_weights('gan.h5')\n",
    "        \n",
    "        print(f'step {step}: discriminator loss: {d_loss}, adversarial loss: {a_loss}')\n",
    "        \n",
    "        img = image.array_to_img(generated_images[0] * 255., scale=False)\n",
    "        img.save(os.path.join(save_dir, f'generated_frog_{step}.png'))\n",
    "        \n",
    "        img = image.array_to_img(real_images[0] * 255., scale=False)\n",
    "        img.save(os.path.join(save_dir, f'real_frog_{step}.png'))\n",
    "    else:\n",
    "        time_cost = end_time - start_time\n",
    "        time_eta = time_cost * (iterations - step)\n",
    "        print(f'{step}/{iterations}: {time_cost:.2f}s - ETA: {time_eta:.0f}s', end='\\r')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1000: discriminator loss: 0.7096449136734009, adversarial loss: 0.752526581287384\n"
     ]
    }
   ],
   "source": [
    "for step in range(iterations, iterations+1):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # éšæœºé‡‡æ ·æ½œåœ¨ç‚¹\n",
    "    random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\n",
    "    \n",
    "    # ç”Ÿæˆå›¾åƒ\n",
    "    generated_images = generator.predict(random_latent_vectors)\n",
    "    \n",
    "    # é€‰å–çœŸå®å›¾åƒ\n",
    "    stop = start + batch_size\n",
    "    real_images = x_train[start: stop]\n",
    "    \n",
    "    # åˆå¹¶ç”Ÿæˆã€çœŸå®å›¾åƒï¼Œç»™å‡ºæ ‡ç­¾\n",
    "    combined_images = np.concatenate([generated_images, real_images])\n",
    "    labels = np.concatenate([np.ones((batch_size, 1)),\n",
    "                             np.zeros((batch_size, 1))])\n",
    "    labels += 0.05 * np.random.random(labels.shape)  # å‘æ ‡ç­¾ä¸­æ·»åŠ éšæœºå™ªå£°\n",
    "    \n",
    "    # è®­ç»ƒåˆ¤åˆ«å™¨\n",
    "    d_loss = discriminator.train_on_batch(combined_images, labels)\n",
    "    \n",
    "    # éšæœºé‡‡æ ·æ½œåœ¨ç‚¹\n",
    "    random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\n",
    "    \n",
    "    misleading_targets = np.zeros((batch_size, 1))  # è°ç§°å…¨éƒ¨éƒ½æ˜¯çœŸå®å›¾ç‰‡\n",
    "    \n",
    "    # é€šè¿‡ gan æ¨¡å‹è®­ç»ƒç”Ÿæˆå™¨\n",
    "    a_loss = gan.train_on_batch(random_latent_vectors, misleading_targets)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    start += batch_size\n",
    "    if start > len(x_train) - batch_size:\n",
    "        start = 0\n",
    "        \n",
    "    if step % 50 == 0:\n",
    "        gan.save_weights('gan.h5')\n",
    "        \n",
    "        print(f'step {step}: discriminator loss: {d_loss}, adversarial loss: {a_loss}')\n",
    "        \n",
    "        img = image.array_to_img(generated_images[0] * 255., scale=False)\n",
    "        img.save(os.path.join(save_dir, f'generated_frog_{step}.png'))\n",
    "        \n",
    "        img = image.array_to_img(real_images[0] * 255., scale=False)\n",
    "        img.save(os.path.join(save_dir, f'real_frog_{step}.png'))\n",
    "    else:\n",
    "        time_cost = end_time - start_time\n",
    "        time_eta = time_cost * (iterations - step)\n",
    "        print(f'{step}/{iterations}: {time_cost:.2f}s - ETA: {time_eta:.0f}s', end='\\r')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æœ€åè¾“å‡ºçš„å›¾åƒï¼š\n",
    "\n",
    "![æœ€åè¾“å‡ºçš„å›¾åƒ](https://tva1.sinaimg.cn/large/007S8ZIlgy1gi27n2ulptj300w00w0si.jpg)\n",
    "\n",
    "æ•ˆæœç›¸å½“å·®ã€‚è¿™ä¸ªä¸œè¥¿è®­ç»ƒæ¶ˆè€—å¤ªå¤§äº†ï¼Œåˆæ˜¯ CPU åŠé€€ï¼Œæˆ‘åªè·‘äº† 1000 è½®ï¼Œè¿˜å¤ªå°‘äº†ã€‚ã€‚ã€‚ä¸æ„§ä¸ºå…¨ä¹¦æœ€åä¸€é¢˜ï¼Œå‹è½´ï¼Œè¿™å°é’è›™å›¾æˆ‘ä¸è¦äº†ã€‚ğŸ˜‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
