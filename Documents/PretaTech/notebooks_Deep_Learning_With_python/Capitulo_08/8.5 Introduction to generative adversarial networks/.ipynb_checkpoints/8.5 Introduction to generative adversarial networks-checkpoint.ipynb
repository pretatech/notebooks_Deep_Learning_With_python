{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aprendizado profundo com Python\n",
    "\n",
    "## 8.5 Introdução às redes adversárias geradoras\n",
    "\n",
    "> Introdução às Redes Adversariais Gerativas\n",
    "\n",
    "GAN, chinês é ~~ gan ~~, errado, Generative Adversarial Network. Como VAE, é usado para aprender o espaço latente da imagem. Isso pode tornar a imagem gerada \"estatisticamente\" igual à imagem real, ou seja, a imagem gerada é bastante realista. No entanto, ao contrário do VAE, o espaço latente de GAN não pode ser garantido como tendo uma estrutura significativa e não é contínuo.\n",
    "\n",
    "GAN consiste em duas partes:\n",
    "\n",
    "-Rede geradora: insira um vetor aleatório (um ponto aleatório no espaço latente) e decodifique-o em uma imagem.\n",
    "- Rede discriminadora: Insira uma imagem (real ou desenhada pelo gerador) e preveja se a imagem é real ou criada pela rede do gerador. (A rede discriminadora também é chamada de \"adversário\", adversário)\n",
    "\n",
    "O objetivo do treinamento do GAN é permitir que a \"rede geradora\" engane a \"rede discriminadora\".\n",
    "\n",
    "A compreensão intuitiva de GAN é uma história muito inspiradora: ou seja, há duas pessoas, um falsificador e um avaliador. Os falsificadores imitam as pinturas do mestre e, em seguida, misturam suas imitações com as originais e as submetem ao avaliador para avaliação, que avalia a autenticidade de cada pintura e vê através de quais são forjadas. O amável avaliador deu feedback ao falsificador e disse-lhe as características do original. Os falsificadores irão, passo a passo, melhorar sua capacidade de falsificação com base nas opiniões do avaliador. Os dois repetiram esse processo incansavelmente: os falsificadores tornaram-se cada vez mais bons em copiar pinturas de mestres e os avaliadores se tornaram cada vez mais bons em encontrar pinturas falsas. No final, os falsificadores criaram um lote de \"produtos de imitação\" que os avaliadores impõem.\n",
    "\n",
    "! [O gerador converte o vetor latente aleatório em uma imagem e o discriminador tenta distinguir a imagem real da imagem gerada. O gerador é treinado para enganar o discriminador] (https://tva1.sinaimg.cn/large/007S8ZIlgy1ghva0rve82j31ec0tcthm.jpg)\n",
    "\n",
    "O método de treinamento do GAN é muito especial e seu mínimo otimizado não é fixo. Nossa \"descida gradiente\" usual é rolar montanha abaixo ao longo do terreno de perda estática, mas cada degrau da montanha durante o treinamento GAN mudará todo o terreno. É um sistema dinâmico e seu processo de otimização é o equilíbrio entre duas forças. Portanto, GAN é difícil de treinar. Para fazer o GAN funcionar normalmente, é necessário muito trabalho de construção de modelo e ajuste de hiperparâmetro.\n",
    "\n",
    "### Rede Adversarial Gerativa Convolucional Profunda\n",
    "\n",
    "Vamos tentar implementar o GAN mais simples e simples com Keras. Especificamente, construiremos uma ** rede convolucional profunda de confronto gerador ** (GAN convolucional profunda, DCGAN). O gerador e o discriminador desse tipo de coisa são ambas redes neurais convolucionais profundas.\n",
    "\n",
    "Vamos treinar DCGAN com imagens da categoria \"sapo\" no conjunto de dados CIFAR10. Este conjunto de dados contém 50000 imagens RGB 32 × 32, que pertencem a 10 categorias (5000 imagens em cada categoria).\n",
    "\n",
    "#### Processo de implementação\n",
    "\n",
    "1. A rede `generator` mapeia um vetor de forma` (latent_dim,) `para uma imagem de forma` (32, 32, 3) `.\n",
    "2. A rede `discriminator` mapeia a imagem com a forma` (32, 32, 3) `para uma pontuação binária, que é usada para avaliar a probabilidade de a imagem ser verdadeira.\n",
    "3. A rede `gan` conecta` gerador` e `discriminador` juntos:` gan (x) = discriminador (gerador (x)) `. Esta rede mapeia o vetor latente para o resultado da avaliação do discriminador.\n",
    "4. Use as amostras de imagens verdadeiras e falsas rotuladas com `\" real \"` ou `\" falsa \"` para treinar o discriminador e use o método usual de treinar modelos de classificação de imagem comuns.\n",
    "5. Para treinar o gerador, use o gradiente de perda do modelo `gan` em relação ao peso do gerador. A cada etapa, o peso do gerador deve ser movido para \"tornar o discriminador mais provável de classificar a imagem decodificada pelo gerador como\" verdadeira \"\", ou seja, treinar o gerador para enganar o discriminador.\n",
    "\n",
    "#### Habilidades práticas\n",
    "\n",
    "O processo de treinamento e ajuste do GAN é muito difícil. Portanto, precisamos nos lembrar de algumas habilidades práticas resumidas por pessoas anteriores. Essas técnicas geralmente são úteis, mas não se aplicam a todas as situações. Essas coisas não têm base teórica, são todas metafísicas, então escreva a conclusão diretamente, sem explicação:\n",
    "\n",
    "-Use tanh como a ativação da última camada do gerador em vez de sigmóide.\n",
    "-Use a distribuição normal (distribuição gaussiana) para amostrar pontos no espaço latente em vez da distribuição uniforme.\n",
    "-A aleatoriedade pode melhorar a robustez. O treinamento GAN pode ficar \"preso\" de várias maneiras (atingindo o equilíbrio dinâmico errado). A introdução da aleatoriedade durante o processo de treinamento ajuda a prevenir essa situação. Existem duas maneiras de introduzir a aleatoriedade:\n",
    "    1. Use dropout no discriminador;\n",
    "    2. Adicione ruído aleatório ao rótulo do discriminador;\n",
    "- Gradiente esparso atrapalhará o treinamento GAN \"Operação máxima de pooling\" e \"ativação ReLU\" podem levar a gradientes esparsos, por isso é recomendado:\n",
    "    1. Use `` convolução em etapas '' ao invés de `` max pooling '' para reduzir a resolução;\n",
    "    2. Use a camada LeakyReLU para substituir a ativação ReLU;\n",
    "-Nas imagens geradas, artefatos quadriculados são frequentemente vistos, o que se deve à cobertura desigual do espaço do pixel no gerador. A solução para este problema é: sempre que o passo Conv2DTranpose ou Conv2D é usado no gerador e discriminador, o tamanho do kernel deve ser divisível pelo passo.\n",
    "\n",
    "\n",
    "\n",
    "Imagem de exemplo de artefatos de tabuleiro de xadrez devido à incompatibilidade de tamanho da passada e tamanho do kernel:\n",
    "\n",
    "! [Artefatos do tabuleiro de damas devido à incompatibilidade de tamanho da passada e tamanho do kernel] (https://tva1.sinaimg.cn/large/007S8ZIlgy1ghvayd7ipwj31560ggazl.jpg)\n",
    "\n",
    "#### A realização do gerador\n",
    "\n",
    "Comecei a construir o primeiro GAN para jovens! !\n",
    "\n",
    "Primeiro desenvolva o modelo do gerador: converta o vetor do espaço latente em uma imagem candidata.\n",
    "\n",
    "Para evitar \"travar\" durante o treinamento, o dropout é usado tanto no discriminador quanto no gerador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32)]              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32768)             1081344   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 16, 16, 256)       819456    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 32, 32, 256)       1048832   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 256)       1638656   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 256)       1638656   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 3)         37635     \n",
      "=================================================================\n",
      "Total params: 6,264,579\n",
      "Trainable params: 6,264,579\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# GAN Rede Geradora\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "height = 32\n",
    "width = 32\n",
    "channels = 3\n",
    "\n",
    "latent_dim = 32\n",
    "\n",
    "generator_input = keras.Input(shape=(latent_dim,))\n",
    "\n",
    "# Converta a entrada em um mapa de recursos de 128 canais com um tamanho de 16 × 16\n",
    "x = layers.Dense(128 * 16 * 16)(generator_input)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Reshape((16, 16, 128))(x)\n",
    "\n",
    "x = layers.Conv2D(256, 5, padding='same')(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "# A amostragem de aumento é de 32 × 32\n",
    "x = layers.Conv2DTranspose(256, 4, strides=2, padding='same')(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Conv2D(256, 5, padding='same')(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2D(256, 5, padding='same')(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "# Gere um mapa de recursos de tamanho 32 × 32 (o formato da imagem CIFAR10)\n",
    "x = layers.Conv2D(channels, 7, activation='tanh', padding='same')(x)\n",
    "\n",
    "generator = keras.models.Model(generator_input, x)\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementação do discriminador\n",
    "\n",
    "Em seguida, desenvolva o modelo discriminador, insira uma imagem (real ou sintética) e divida-a em \"verdadeiro\" (imagem real do conjunto de treinamento) ou \"falso\" (imagem desenhada pelo gerador)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 30, 30, 128)       3584      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 30, 30, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 14, 14, 128)       262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 6, 6, 128)         262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 2, 2, 128)         262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 790,913\n",
      "Trainable params: 790,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# GAN Rede discriminadora\n",
    "\n",
    "discriminator_input = layers.Input(shape=(height, width, channels))\n",
    "\n",
    "x = layers.Conv2D(128, 3)(discriminator_input)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Conv2D(128, 4, strides=2)(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Conv2D(128, 4, strides=2)(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Conv2D(128, 4, strides=2)(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dropout(0.4)(x)\n",
    "\n",
    "x = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "discriminator = keras.models.Model(discriminator_input, x)\n",
    "discriminator.summary()\n",
    "\n",
    "discriminator_optimizer = keras.optimizers.RMSprop(\n",
    "    lr=0.0008,\n",
    "    clipvalue=1.0,\n",
    "    decay=1e-8)\n",
    "\n",
    "discriminator.compile(optimizer=discriminator_optimizer,\n",
    "                      loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confrontando a Internet\n",
    "\n",
    "Finalmente, configure o GAN, conecte o gerador e o discriminador e converta os pontos no espaço latente em um julgamento de classificação verdadeiro ou falso.\n",
    "\n",
    "Ao treinar este modelo, é necessário congelar o “discriminador” (torná-lo intratável), e apenas permitir que o “gerador” se mova na direção de “melhorar a habilidade do discriminador de engano”.\n",
    "\n",
    "Ao treinar gan, tudo o que usamos são os rótulos de \"imagens reais\", portanto, se o peso do \"discriminador\" puder ser atualizado durante o processo de treinamento, o treinamento fará com que o discriminador sempre preveja \"verdadeiro\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rede de Confronto\n",
    "\n",
    "discriminator.trainable = False    # Isso só funcionará em gan\n",
    "\n",
    "gan_input = keras.Input(shape=(latent_dim,))\n",
    "gan_output = discriminator(generator(gan_input))\n",
    "gan = keras.models.Model(gan_input, gan_output)\n",
    "\n",
    "gan_optimizer = keras.optimizers.RMSprop(\n",
    "    lr=0.0004,\n",
    "    clipvalue=1.0,\n",
    "    decay=1e-8)\n",
    "gan.compile(optimizer=gan_optimizer,\n",
    "            loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treine DCGAN\n",
    "\n",
    "O fluxo do loop de treinamento é o seguinte:\n",
    "\n",
    "1. Extraia pontos aleatórios (ruído aleatório) do espaço latente.\n",
    "2. Dê este ruído aleatório ao gerador para gerar uma imagem.\n",
    "3. Misture a imagem gerada com a imagem real.\n",
    "4. Use essas imagens misturadas e os rótulos correspondentes (a imagem real é \"verdadeira\" e a imagem gerada é \"falsa\") para treinar o discriminador.\n",
    "5. Desenhe aleatoriamente novos pontos no espaço latente.\n",
    "6. Use esses vetores e rótulos aleatórios que são \"imagens reais\" para treinar gan.\n",
    "\n",
    "Implementação de código específico:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: discriminator loss: 0.6944685578346252, adversarial loss: 0.7566524744033813\n",
      "step 50: discriminator loss: 0.6997207999229431, adversarial loss: 0.7283448576927185\n",
      "step 100: discriminator loss: 0.6917451024055481, adversarial loss: 0.7818207144737244\n",
      "step 150: discriminator loss: 0.7006672620773315, adversarial loss: 0.77472984790802\n",
      "step 200: discriminator loss: 0.6959202885627747, adversarial loss: 0.7540444731712341\n",
      "step 250: discriminator loss: 0.6907225847244263, adversarial loss: 0.7319836020469666\n",
      "step 300: discriminator loss: 0.6964272856712341, adversarial loss: 0.795426070690155\n",
      "step 350: discriminator loss: 0.7021819949150085, adversarial loss: 0.7412662506103516\n",
      "step 400: discriminator loss: 0.6954243183135986, adversarial loss: 0.7441832423210144\n",
      "step 450: discriminator loss: 0.7256754636764526, adversarial loss: 0.7400968074798584\n",
      "step 500: discriminator loss: 0.7020201683044434, adversarial loss: 0.7446410059928894\n",
      "step 550: discriminator loss: 0.6801480054855347, adversarial loss: 0.9143943786621094\n",
      "step 600: discriminator loss: 0.6830952763557434, adversarial loss: 0.7880680561065674\n",
      "step 650: discriminator loss: 0.7454708218574524, adversarial loss: 0.782561182975769\n",
      "step 700: discriminator loss: 0.6792200803756714, adversarial loss: 0.7939407825469971\n",
      "step 750: discriminator loss: 0.6916797757148743, adversarial loss: 0.8157812356948853\n",
      "step 800: discriminator loss: 0.6902390718460083, adversarial loss: 0.750106692314148\n",
      "step 850: discriminator loss: 0.6986071467399597, adversarial loss: 0.7653893232345581\n",
      "step 900: discriminator loss: 0.7069215774536133, adversarial loss: 0.7258030772209167\n",
      "step 950: discriminator loss: 0.6925474405288696, adversarial loss: 0.7341045141220093\n",
      "999/1000: 12.41s - ETA: 12ss\r"
     ]
    }
   ],
   "source": [
    "# GAN Treinamento,\n",
    "\n",
    "import os\n",
    "import time\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Importar dados CIFAR10\n",
    "(x_train, y_train), (_, _) = keras.datasets.cifar10.load_data()\n",
    "# Selecione a imagem do sapo🐸\n",
    "x_train = x_train[y_train.flatten() == 6]\n",
    "\n",
    "x_train = x_train.reshape(\n",
    "    (x_train.shape[0],) + (height, width, channels)\n",
    ").astype('float32') / 255.\n",
    "\n",
    "\n",
    "iterations = 10000\n",
    "batch_size = 20\n",
    "save_dir = 'gan_save'\n",
    "\n",
    "start = 0\n",
    "for step in range(iterations+1):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Amostra aleatoriamente de pontos potenciais\n",
    "    random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\n",
    "    \n",
    "    # Gerar imagem\n",
    "    generated_images = generator.predict(random_latent_vectors)\n",
    "    \n",
    "    # Escolha uma imagem real\n",
    "    stop = start + batch_size\n",
    "    real_images = x_train[start: stop]\n",
    "    \n",
    "    # Combine imagens reais e geradas e dê rótulos\n",
    "    combined_images = np.concatenate([generated_images, real_images])\n",
    "    labels = np.concatenate([np.ones((batch_size, 1)),\n",
    "                             np.zeros((batch_size, 1))])\n",
    "    labels += 0.05 * np.random.random(labels.shape)  # Adicionar ruído aleatório ao rótulo\n",
    "    \n",
    "    # 训练判别器\n",
    "    d_loss = discriminator.train_on_batch(combined_images, labels)\n",
    "    \n",
    "    # 随机采样潜在点\n",
    "    random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\n",
    "    \n",
    "    misleading_targets = np.zeros((batch_size, 1))  # 谎称全部都是真实图片\n",
    "    \n",
    "    # 通过 gan 模型训练生成器\n",
    "    a_loss = gan.train_on_batch(random_latent_vectors, misleading_targets)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    start += batch_size\n",
    "    if start > len(x_train) - batch_size:\n",
    "        start = 0\n",
    "        \n",
    "    if step % 50 == 0:\n",
    "        gan.save_weights('gan.h5')\n",
    "        \n",
    "        print(f'step {step}: discriminator loss: {d_loss}, adversarial loss: {a_loss}')\n",
    "        \n",
    "        img = image.array_to_img(generated_images[0] * 255., scale=False)\n",
    "        img.save(os.path.join(save_dir, f'generated_frog_{step}.png'))\n",
    "        \n",
    "        img = image.array_to_img(real_images[0] * 255., scale=False)\n",
    "        img.save(os.path.join(save_dir, f'real_frog_{step}.png'))\n",
    "    else:\n",
    "        time_cost = end_time - start_time\n",
    "        time_eta = time_cost * (iterations - step)\n",
    "        print(f'{step}/{iterations}: {time_cost:.2f}s - ETA: {time_eta:.0f}s', end='\\r')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1000: discriminator loss: 0.7096449136734009, adversarial loss: 0.752526581287384\n"
     ]
    }
   ],
   "source": [
    "for step in range(iterations, iterations+1):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # 随机采样潜在点\n",
    "    random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\n",
    "    \n",
    "    # 生成图像\n",
    "    generated_images = generator.predict(random_latent_vectors)\n",
    "    \n",
    "    # 选取真实图像\n",
    "    stop = start + batch_size\n",
    "    real_images = x_train[start: stop]\n",
    "    \n",
    "    # 合并生成、真实图像，给出标签\n",
    "    combined_images = np.concatenate([generated_images, real_images])\n",
    "    labels = np.concatenate([np.ones((batch_size, 1)),\n",
    "                             np.zeros((batch_size, 1))])\n",
    "    labels += 0.05 * np.random.random(labels.shape)  # 向标签中添加随机噪声\n",
    "    \n",
    "    # 训练判别器\n",
    "    d_loss = discriminator.train_on_batch(combined_images, labels)\n",
    "    \n",
    "    # 随机采样潜在点\n",
    "    random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\n",
    "    \n",
    "    misleading_targets = np.zeros((batch_size, 1))  # 谎称全部都是真实图片\n",
    "    \n",
    "    # 通过 gan 模型训练生成器\n",
    "    a_loss = gan.train_on_batch(random_latent_vectors, misleading_targets)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    start += batch_size\n",
    "    if start > len(x_train) - batch_size:\n",
    "        start = 0\n",
    "        \n",
    "    if step % 50 == 0:\n",
    "        gan.save_weights('gan.h5')\n",
    "        \n",
    "        print(f'step {step}: discriminator loss: {d_loss}, adversarial loss: {a_loss}')\n",
    "        \n",
    "        img = image.array_to_img(generated_images[0] * 255., scale=False)\n",
    "        img.save(os.path.join(save_dir, f'generated_frog_{step}.png'))\n",
    "        \n",
    "        img = image.array_to_img(real_images[0] * 255., scale=False)\n",
    "        img.save(os.path.join(save_dir, f'real_frog_{step}.png'))\n",
    "    else:\n",
    "        time_cost = end_time - start_time\n",
    "        time_eta = time_cost * (iterations - step)\n",
    "        print(f'{step}/{iterations}: {time_cost:.2f}s - ETA: {time_eta:.0f}s', end='\\r')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后输出的图像：\n",
    "\n",
    "![最后输出的图像](https://tva1.sinaimg.cn/large/007S8ZIlgy1gi27n2ulptj300w00w0si.jpg)\n",
    "\n",
    "效果相当差。这个东西训练消耗太大了，又是 CPU 劝退，我只跑了 1000 轮，还太少了。。。不愧为全书最后一题，压轴，这封青蛙图我不要了。😂"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
