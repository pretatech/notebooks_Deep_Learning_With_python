{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning with Python\n",
    "2.1 A first look at a neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de mais nada os notebooks aqui mostrado tiveram como base/foram retirados dos seguintes reposit√≥rios: \n",
    " > https://github.com/fchollet/deep-learning-with-python-notebooks \n",
    " \n",
    " \n",
    " > https://github.com/cdfmlr/Deep-Learning-with-Python-Notebooks\n",
    " \n",
    " Sugiro fortemente que consultem os c√≥digos originais e em caso de d√∫vida podem me contatar para conversarmos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos come√ßar nossos estudos pr√°ticos de DeepLearning construindo nossa primeira rede neural. Para isso vamos utilizar a base de dados do MNIST, um cl√°ssico dataset na comunidade de machinelearning. S√£o diversas imagens em escala de cinza escritas a m√£o de digitos de 0 a 9 no tamanho de 28x28 pixels. O conjunto tem 60000 imagens de treino e mais 10000 de teste. \n",
    "Para mais informa√ß√µes sobre o conjunto: http://yann.lecun.com/exdb/mnist/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando a base de dados MNIST no Keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vamos dar uma olhada no tamanho dos dados de treinamento\n",
    "print(train_images.shape)\n",
    "print(train_labels.shape)\n",
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vamos dar uma olhada no tamanho dos dados de teste\n",
    "print(test_images.shape)\n",
    "print(test_labels.shape)\n",
    "test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nosso fluxo de trabalho ser√° o seguinte: primeiro apresentaremos nossa rede neural com os dados de treinamento, train_images e train_labels. A rede aprender√° a associar imagens e r√≥tulos. Finalmente, pediremos √† rede para produzir previs√µes para test_images e verificaremos se essas previs√µes correspondem aos r√≥tulos de test_labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28, )))\n",
    "network.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.compile(loss=\"categorical_crossentropy\",\n",
    "                optimizer='rmsprop',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes do treinamento, √© preciso passar os dados por um pr√©-processamento, de forma a remodelar essa informa√ß√£o para que a rede neural compreenda, ou seja, deixar em dimens√µes comprees√≠veis para a rede. Nesse caso dimensionando-os de forma que todos os valores fiquem no intervalo [0, 1]. Anteriormente, nossas imagens de treinamento, por exemplo, eram armazenadas em uma matriz de forma (60000, 28, 28) do tipo uint8 com valores no intervalo [0, 255]. N√≥s o transformamos em uma matriz float32 de forma (60000, 28 * 28) com valores entre 0 e 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora estamos prontos para treinar nossa rede! Aqui n√≥s vamos \"fitar\" o modelo, ou seja, ajudar a rede que constru√≠mos, fazendo o \"fit\" do modelo aos dados de treinamento que temos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 0.2510 - accuracy: 0.9283\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 0.1014 - accuracy: 0.9696\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 0.0671 - accuracy: 0.9802\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 0.0488 - accuracy: 0.9855\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 0.0372 - accuracy: 0.9888\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x28fef89b6c8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duas quantidades est√£o sendo exibidas durante o treinamento: a \"perda\" (loss) da rede nos dados de treinamento e a acur√°cia (accurancy) da rede nos dados de treinamento.\n",
    "\n",
    "Alcan√ßamos rapidamente uma acur√°cia de 0,989 (ou seja, 98,9%) nos dados de treinamento. Agora vamos verificar se nosso modelo tem um bom desempenho no conjunto de teste tamb√©m:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 - 1s - loss: 0.0654 - accuracy: 0.9814\n",
      "test_acc: 0.9814\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = network.evaluate(test_images, test_labels, verbose=2)   \n",
    "# Colocamos o param√™tro verbose=2 para evitar um processo muito grande que enche a tela com \"=\". Podemos ver aqui:  https://github.com/tensorflow/tensorflow/issues/32286\n",
    "print('test_acc:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Massa demais!! Conseguimos ent√£o uma acur√°cia de 98,14% no conjunto de teste. Um valor muito bom!üëèüèæüëèüèæüëèüèæüëèüèæ Mas vamos continuar nossos estudos! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
